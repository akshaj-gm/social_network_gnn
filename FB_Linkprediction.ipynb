{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456ed869-89ab-4610-bbf8-c0d89d503c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
      "Requirement already satisfied: torch-scatter in /Users/akshaj.g/mamba/lib/python3.10/site-packages (2.1.1)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
      "Requirement already satisfied: torch-sparse in /Users/akshaj.g/mamba/lib/python3.10/site-packages (0.6.17)\n",
      "Requirement already satisfied: scipy in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-sparse) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from scipy->torch-sparse) (1.24.1)\n",
      "Requirement already satisfied: torch-geometric in /Users/akshaj.g/mamba/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: numpy in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (1.24.1)\n",
      "Requirement already satisfied: scipy in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (1.10.0)\n",
      "Requirement already satisfied: jinja2 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: pyparsing in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (5.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install torch geometric\n",
    "import os\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
    "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
    "  !pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5110e1-9a6d-4276-82ee-88b20e5e06c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/akshaj.g/mamba/lib/python3.10/site-packages (23.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7124823-9dc4-4764-8769-9bc6d4aec5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66339363-231b-497f-afd5-b193fd0557ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "import scipy.sparse\n",
    "from torch import Tensor\n",
    "from torch.utils.dlpack import from_dlpack, to_dlpack\n",
    "\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146dd7cd-5493-4efd-9149-5771d1000f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('/Users/akshaj.g/Desktop/ml/social network /FacebookRecruiting/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed28148c-1471-4e51-9bbc-db800cbff9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862220\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor(train.values).T\n",
    "num_nodes = edge_index.max().item()\n",
    "print(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8b5d7f-6b9f-44a1-89bb-f5fd7ef0088e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9437519])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54e3785-c79a-4178-9032-2866473278d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_scipy_sparse_matrix(\n",
    "    edge_index: Tensor,\n",
    "    edge_attr: Optional[Tensor] = None,\n",
    "    num_nodes: Optional[int] = None,\n",
    ") -> scipy.sparse.coo_matrix:\n",
    "    row, col = edge_index.cpu()\n",
    "\n",
    "    if edge_attr is None:\n",
    "        edge_attr = torch.ones(row.size(0))\n",
    "    else:\n",
    "        edge_attr = edge_attr.view(-1).cpu()\n",
    "        assert edge_attr.size(0) == row.size(0)\n",
    "\n",
    "    N = maybe_num_nodes(edge_index, num_nodes)\n",
    "    out = scipy.sparse.coo_matrix(\n",
    "        (edge_attr.numpy(), (row.numpy(), col.numpy())), (N, N))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91a32f8-7cda-4f48-80a4-21396933002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat=to_scipy_sparse_matrix(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3402570b-1e98-43b5-ba11-ea1b3ba765fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensordict in /Users/akshaj.g/mamba/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: torch in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from tensordict) (1.13.1)\n",
      "Requirement already satisfied: numpy in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from tensordict) (1.24.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from tensordict) (2.2.1)\n",
      "Requirement already satisfied: typing_extensions in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch->tensordict) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensordict\n",
    "import torch.nn as nn\n",
    "from tensordict import TensorDict\n",
    "from tensordict.nn import TensorDictModule, TensorDictSequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "491e11e2-b6cd-46f5-bf4f-d318da78eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features=defaultdict(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b493308-f5b9-44a6-b242-c8b353a77ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_degree(edge_list, adj_mat, num_nodes):\n",
    "  degree=torch.tensor(adj_mat.sum(axis=1).A1, dtype=torch.long)\n",
    "  degree = torch.where(degree > 0, degree, torch.zeros_like(degree))\n",
    "  if degree.shape[0] < num_nodes:\n",
    "    degree = torch.cat((degree, torch.zeros(num_nodes - degree.shape[0], dtype=torch.long)))\n",
    "\n",
    "  return degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0804ea-287b-453c-9a5b-2a4a42022004",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_t=node_degree(edge_index,adj_mat,num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d46c961-9332-46d1-9a5c-86f5fb57b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        conv_model = self.build_conv_model(args.model_type)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
    "\n",
    "\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = args.dropout\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "\n",
    "    def build_conv_model(self, model_type):\n",
    "        if model_type == 'GraphSage':\n",
    "            return GraphSage\n",
    "        elif model_type == 'GAT':\n",
    "            return GAT\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        if self.emb:\n",
    "            return x\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491c23e3-71f6-4f55-b4a8-475078dbeb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSage(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, normalize = True,\n",
    "                 bias = False, **kwargs):  \n",
    "        super(GraphSage, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "        self.lin_l = nn.Linear(self.in_channels, self.out_channels)\n",
    "        self.lin_r = nn.Linear(self.in_channels, self.out_channels)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        out = None\n",
    "        prop=self.propagate(edge_index, x=(x, x), size=size)\n",
    "        out=self.lin_l(x) + self.lin_r(prop)\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "\n",
    "        out = None\n",
    "        out = x_j\n",
    "        return out\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        out = None\n",
    "        node_dim = self.node_dim\n",
    "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce='mean')\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afe94c64-52de-4e2b-ab08-8644f28f122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, heads = 2,\n",
    "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
    "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "        self.att_l = None\n",
    "        self.att_r = None\n",
    "\n",
    "        self.lin_l = nn.Linear(self.in_channels, self.heads*self.out_channels)\n",
    "        self.lin_r = self.lin_l\n",
    "        self.att_l = nn.Parameter(torch.zeros(self.heads, self.out_channels))\n",
    "        self.att_r=self.att_l\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
    "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
    "        nn.init.xavier_uniform_(self.att_l)\n",
    "        nn.init.xavier_uniform_(self.att_r)\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "\n",
    "        H, C = self.heads, self.out_channels\n",
    "        x_l=self.lin_l(x).view(-1, H, C)\n",
    "        x_r=self.lin_r(x).view(-1, H, C)\n",
    "        alpha_l=self.att_l*x_l\n",
    "        alpha_r=self.att_r*x_r\n",
    "        out=self.propagate(edge_index, x=(x_l,x_r), alpha=(alpha_l, alpha_r), size=size).view(-1,H*C)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
    "        alpha=(alpha_j + alpha_i).squeeze(-1)\n",
    "        alpha=F.leaky_relu(alpha, negative_slope=0.2)\n",
    "        if ptr:\n",
    "            alpha = F.softmax(alpha,ptr)\n",
    "        else:\n",
    "            alpha=torch_geometric.utils.softmax(alpha, index)\n",
    "        alpha=F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        out=x_j * alpha\n",
    "        return out\n",
    "\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "        node_dim = self.node_dim\n",
    "        out = torch_scatter.scatter(inputs, index, node_dim, dim_size=dim_size, reduce='sum')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99809f80-3321-43d9-8330-b58f9dea92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_edges=edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25efbdfd-962f-495e-b06e-2dac493ef197",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('/Users/akshaj.g/Desktop/ml/social network /FacebookRecruiting/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d0da67b-7fbc-4397-9156-e21ac24c44b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9437519])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = torch.tensor(test.values).T\n",
    "test_index.shape\n",
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "321e435e-1a59-42be-afd0-d759dfc8e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c84b4456-cae1-42af-96aa-aa9a55553711",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edges=negative_sampling(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19cb33a2-4cf4-4f1c-a051-b4e316a17e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9437519])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15c5832d-0d51-4b9c-ad78-43bbdc9da1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label = torch.tensor(([1.] * 100 + [0.] * 100),requires_grad=True)\n",
    "edge_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31ef4a26-14c3-493d-9a5a-5fcd73e31c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_node_index = max(positive_edges.max(), neg_edges.max())\n",
    "num_nodes = max_node_index + 1\n",
    "x = torch.rand(num_nodes, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "341bb169-4835-4bfb-8211-dbf9bf77ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "def accuracy(pred, label):\n",
    "  accu = 0.0\n",
    "  y_hat = (pred>0.5).type(torch.LongTensor)\n",
    "  accu = torch.mean((label==y_hat).type(torch.FloatTensor))\n",
    "  return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13fab26d-d37a-4d39-98fd-f5fffa241d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00d2e9b0-160e-4009-ae90-cff131b641fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(positive_edges,neg_edges,args,batch_size):\n",
    "#building the model \n",
    "\n",
    "    model = GNNStack(16, args.hidden_dim, 8,args)\n",
    "    \n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "#starting the training \n",
    "\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "#shuffle the edges\n",
    "        p_idx = torch.randperm(positive_edges.size(1))\n",
    "        p=positive_edges[:,p_idx]\n",
    "        p=torch.tensor(p)\n",
    "        n_idx = torch.randperm(neg_edges.size(1))\n",
    "        n=neg_edges[:,n_idx]\n",
    "        n=torch.tensor(n)\n",
    "#batch the edges\n",
    "        p_b = p[:,:batch_size]\n",
    "        n_b = n[:,:batch_size]\n",
    "        train_edge = torch.cat([p_b,n_b], dim=0).T\n",
    "        print(train_edge.shape)\n",
    "        opt.zero_grad()\n",
    "#logic:if they are connected by a edge the dot product=1 else 0 \n",
    "        emb = model.forward(x,edge_index)\n",
    "        positive = sigmoid(torch.bmm(emb[train_edge[:, 0]].unsqueeze(1), emb[train_edge[:, 1]].unsqueeze(2)).squeeze())\n",
    "        negative = sigmoid(torch.bmm(emb[train_edge[:, 2]].unsqueeze(1), emb[train_edge[:, 3]].unsqueeze(2)).squeeze())\n",
    "        edge_feature = torch.cat([positive , negative])\n",
    "        print(edge_feature.shape)\n",
    "        edge_label = torch.cat([torch.ones(batch_size), torch.zeros(batch_size)], dim=0)\n",
    "        print(edge_label.shape)\n",
    "#loss is binary cross loss \n",
    "            \n",
    "        loss = loss_fn(edge_feature,edge_label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        acc = accuracy(edge_feature , edge_label)\n",
    "        print(emb)\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {acc}\")\n",
    "    node_embeddings = emb.detach()\n",
    "    return node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2f9b444-7e65-47e2-90c1-95cab3ea4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c2e6276-63ce-4490-8055-c38528ded1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/500 [00:00<?, ?Epochs/s]/var/folders/_2/2n3n9_3x6ml82z7y8mx8sgbm0000gn/T/ipykernel_50982/1056206024.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p=torch.tensor(p)\n",
      "/var/folders/_2/2n3n9_3x6ml82z7y8mx8sgbm0000gn/T/ipykernel_50982/1056206024.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  n=torch.tensor(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 4])\n",
      "torch.Size([20000])\n",
      "torch.Size([20000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/500 [00:06<56:14,  6.76s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9799, -2.0754, -2.3426,  ..., -1.9023, -2.2094, -1.8673],\n",
      "        [-2.2212, -2.1008, -2.1321,  ..., -2.0227, -2.2648, -1.8507],\n",
      "        [-1.9951, -2.1122, -2.1703,  ..., -1.9658, -2.2631, -2.0127],\n",
      "        ...,\n",
      "        [-2.0607, -1.9907, -2.1835,  ..., -2.0536, -2.3820, -1.9321],\n",
      "        [-1.9092, -2.2172, -2.3584,  ..., -1.8885, -2.2034, -1.8373],\n",
      "        [-1.9944, -2.1621, -2.2311,  ..., -2.0330, -2.2518, -1.9404]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 1, Loss: 50.0000, Accuracy: 0.5\n",
      "torch.Size([10000, 4])\n",
      "torch.Size([20000])\n",
      "torch.Size([20000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/500 [00:12<50:35,  6.09s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0068, -1.9740, -2.0351,  ..., -2.1459, -2.1291, -2.1017],\n",
      "        [-2.0338, -1.9735, -2.0647,  ..., -2.1223, -2.1161, -2.1251],\n",
      "        [-2.0506, -1.9997, -2.0748,  ..., -2.1300, -2.1046, -2.1412],\n",
      "        ...,\n",
      "        [-2.0619, -2.0056, -2.0686,  ..., -2.1198, -2.1213, -2.1162],\n",
      "        [-2.0650, -1.9791, -2.0438,  ..., -2.1196, -2.1376, -2.1418],\n",
      "        [-2.0724, -1.9900, -2.0584,  ..., -2.1117, -2.1244, -2.0870]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 2, Loss: 50.0000, Accuracy: 0.5\n",
      "torch.Size([10000, 4])\n",
      "torch.Size([20000])\n",
      "torch.Size([20000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 3/500 [00:17<47:43,  5.76s/Epochs]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1803, -2.0448, -1.9853,  ..., -2.1439, -2.0567, -2.1076],\n",
      "        [-2.1319, -2.0756, -2.0105,  ..., -2.1221, -2.0512, -2.1071],\n",
      "        [-2.1591, -2.0810, -2.0054,  ..., -2.1365, -2.0087, -2.1035],\n",
      "        ...,\n",
      "        [-2.1704, -2.0770, -2.0171,  ..., -2.1130, -2.0531, -2.0953],\n",
      "        [-2.1680, -2.0597, -2.0160,  ..., -2.1461, -2.0302, -2.1133],\n",
      "        [-2.1795, -2.0524, -1.9847,  ..., -2.1484, -2.0412, -2.1505]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 3, Loss: 50.0000, Accuracy: 0.5\n",
      "torch.Size([10000, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 3/500 [00:20<57:02,  6.89s/Epochs]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m                 args\u001b[39m.\u001b[39mheads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 15\u001b[0m trained_node_embeddings \u001b[39m=\u001b[39m train(positive_edges, neg_edges, args,\u001b[39m10000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[27], line 46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(positive_edges, neg_edges, args, batch_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m         opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     45\u001b[0m \u001b[39m#logic:if they are connected by a edge the dot product=1 else 0 \u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m         emb \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(x,edge_index)\n\u001b[1;32m     47\u001b[0m         positive \u001b[39m=\u001b[39m sigmoid(torch\u001b[39m.\u001b[39mbmm(emb[train_edge[:, \u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), emb[train_edge[:, \u001b[39m1\u001b[39m]]\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m))\u001b[39m.\u001b[39msqueeze())\n\u001b[1;32m     48\u001b[0m         negative \u001b[39m=\u001b[39m sigmoid(torch\u001b[39m.\u001b[39mbmm(emb[train_edge[:, \u001b[39m2\u001b[39m]]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), emb[train_edge[:, \u001b[39m3\u001b[39m]]\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m))\u001b[39m.\u001b[39msqueeze())\n",
      "Cell \u001b[0;32mIn[14], line 47\u001b[0m, in \u001b[0;36mGNNStack.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[1;32m     46\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m---> 47\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs[i](x, edge_index)\n\u001b[1;32m     48\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     49\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m, in \u001b[0;36mGraphSage.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m prop\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49m(x, x), size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m     26\u001b[0m out\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(x) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_r(prop)\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize:\n",
      "File \u001b[0;32m~/mamba/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:484\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 484\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggr_kwargs)\n\u001b[1;32m    486\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    487\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m, in \u001b[0;36mGraphSage.aggregate\u001b[0;34m(self, inputs, index, dim_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     39\u001b[0m node_dim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim\n\u001b[0;32m---> 40\u001b[0m out \u001b[39m=\u001b[39m torch_scatter\u001b[39m.\u001b[39;49mscatter(inputs, index, dim\u001b[39m=\u001b[39;49mnode_dim, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/mamba/lib/python3.10/site-packages/torch_scatter/scatter.py:156\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_mul(src, index, dim, out, dim_size)\n\u001b[1;32m    155\u001b[0m \u001b[39melif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_mean(src, index, dim, out, dim_size)\n\u001b[1;32m    157\u001b[0m \u001b[39melif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_min(src, index, dim, out, dim_size)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/mamba/lib/python3.10/site-packages/torch_scatter/scatter.py:41\u001b[0m, in \u001b[0;36mscatter_mean\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_mean\u001b[39m(src: torch\u001b[39m.\u001b[39mTensor, index: torch\u001b[39m.\u001b[39mTensor, dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     39\u001b[0m                  out: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m                  dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 41\u001b[0m     out \u001b[39m=\u001b[39m scatter_sum(src, index, dim, out, dim_size)\n\u001b[1;32m     42\u001b[0m     dim_size \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39msize(dim)\n\u001b[1;32m     44\u001b[0m     index_dim \u001b[39m=\u001b[39m dim\n",
      "File \u001b[0;32m~/mamba/lib/python3.10/site-packages/torch_scatter/scatter.py:21\u001b[0m, in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m         size[dim] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     20\u001b[0m     out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(size, dtype\u001b[39m=\u001b[39msrc\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39msrc\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39;49mscatter_add_(dim, index, src)\n\u001b[1;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mscatter_add_(dim, index, src)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    for args in [\n",
    "        {'model_type': 'GraphSage', 'num_layers': 2, 'heads': 1, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.1},\n",
    "    ]:\n",
    "        args = objectview(args)\n",
    "        for model in ['GraphSage']:\n",
    "            args.model_type = model\n",
    "\n",
    "            # Match the dimension.\n",
    "            if model == 'GAT':\n",
    "                args.heads = 2\n",
    "            else:\n",
    "                args.heads = 1\n",
    "                \n",
    "trained_node_embeddings = train(positive_edges, neg_edges, args,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c6f3e9-7df0-4adb-b127-cbf32f3f9de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "866eb63173b86592158a964db75fecf14b959230d80ac60f512e985afb0979db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
