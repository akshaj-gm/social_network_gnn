{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528d806a-a8e7-4c23-9c54-8a8013406802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
      "Requirement already satisfied: torch-scatter in /Users/akshaj.g/mamba/lib/python3.10/site-packages (2.1.1)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
      "Requirement already satisfied: torch-sparse in /Users/akshaj.g/mamba/lib/python3.10/site-packages (0.6.17)\n",
      "Requirement already satisfied: scipy in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-sparse) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from scipy->torch-sparse) (1.24.1)\n",
      "Requirement already satisfied: torch-geometric in /Users/akshaj.g/mamba/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: numpy in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (1.24.1)\n",
      "Requirement already satisfied: scipy in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (1.10.0)\n",
      "Requirement already satisfied: jinja2 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: pyparsing in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from torch-geometric) (5.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/akshaj.g/mamba/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install torch geometric\n",
    "import os\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
    "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.1%2Bcu118.html\n",
    "  !pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbac6c36-7836-4075-9d3e-443c71863c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2346aa6e-455e-438d-978a-ae5eff95f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n",
    "from torch_geometric.data import Data\n",
    "import scipy.sparse\n",
    "from torch import Tensor\n",
    "from torch.utils.dlpack import from_dlpack, to_dlpack\n",
    "\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4d8051-7092-4ef9-bc01-edb02aab162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_edges=pd.read_csv('/Users/akshaj.g/Desktop/ml/social network /FacebookRecruiting/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b344fc15-bdef-46d2-86fc-45d606f4ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862220\n"
     ]
    }
   ],
   "source": [
    "pos_edges = torch.tensor(pos_edges.values).T\n",
    "num_nodes = pos_edges.max().item()\n",
    "print(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b057936-5dbd-4112-bdb1-ac2b550f4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_scipy_sparse_matrix(\n",
    "    edge_index: Tensor,\n",
    "    edge_attr: Optional[Tensor] = None,\n",
    "    num_nodes: Optional[int] = None,\n",
    ") -> scipy.sparse.coo_matrix:\n",
    "    row, col = edge_index.cpu()\n",
    "\n",
    "    if edge_attr is None:\n",
    "        edge_attr = torch.ones(row.size(0))\n",
    "    else:\n",
    "        edge_attr = edge_attr.view(-1).cpu()\n",
    "        assert edge_attr.size(0) == row.size(0)\n",
    "\n",
    "    N = maybe_num_nodes(edge_index, num_nodes)\n",
    "    out = scipy.sparse.coo_matrix(\n",
    "        (edge_attr.numpy(), (row.numpy(), col.numpy())), (N, N))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65fd117-91f3-47d1-88da-d1a8949133ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat=to_scipy_sparse_matrix(pos_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1066b9d8-c03e-4165-9789-f2f193b07b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "x = torch.rand(num_nodes+1, 16)\n",
    "neg_edges=negative_sampling(pos_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706e56cc-882c-430e-a2a3-a2c7d9476c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=pos_edges)\n",
    "data.neg_sampling=neg_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "004903ff-2e54-46c8-b5f5-14c05b5de100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "class GNNStack(torch.nn.Module):                                                   #this makes a subclass of the nn.Module \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):        #instance of the subclass(constructor method)\n",
    "        super(GNNStack, self).__init__()                                           # initiates GNNstack instance \n",
    "        conv_model = self.build_conv_model(args.model_type)                        #building the conv layers (3 for us)         \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
    "\n",
    "\n",
    "        self.post_mp = nn.Sequential(                                                  #post processing dropout\n",
    "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = args.dropout\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "\n",
    "    def build_conv_model(self, model_type):\n",
    "        if model_type == 'GraphSage':\n",
    "            return GraphSage\n",
    "        elif model_type == 'GAT':\n",
    "            return GAT\n",
    "        \n",
    "    def forward(self,data):\n",
    "        x=data.x,pos_edges=data.edge_index\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x,pos_edges)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
    "            \n",
    "        x=self.post_mp(x)\n",
    "        \n",
    "        if self.emb==True:\n",
    "            return x\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_node_embeddings(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=False)  # Set training to False to get deterministic output\n",
    "        return x \n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label) #negative log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c581bf5-fdb5-4201-92e0-313cf0abaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSage(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, normalize = True,\n",
    "                 bias = False, **kwargs):  \n",
    "        super(GraphSage, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Define the layers needed for the message and update functions below.\n",
    "        # self.lin_l is the linear transformation that you apply to embedding \n",
    "        #            for central node.\n",
    "        # self.lin_r is the linear transformation that you apply to aggregated \n",
    "        #            message from neighbors.\n",
    "        # Don't forget the bias!\n",
    "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
    "        self.lin_l = nn.Linear(self.in_channels, self.out_channels, bias=True)\n",
    "        self.lin_r = nn.Linear(self.in_channels, self.out_channels, bias=True)\n",
    "        ############################################################################\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x,pos_edges,neg_edges,size = None):\n",
    "        out = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement message passing, as well as any post-processing (our update rule).\n",
    "        # 1. Call the propagate function to conduct the message passing.\n",
    "        #    1.1 See the description of propagate above or the following link for more information: \n",
    "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "        #    1.2 We will only use the representation for neighbor nodes (x_j), so by default\n",
    "        #        we pass the same representation for central and neighbor nodes as x=(x, x). \n",
    "        # 2. Update our node embedding with skip connection from the previous layer.\n",
    "        # 3. If normalize is set, do L-2 normalization (defined in \n",
    "        #    torch.nn.functional)\n",
    "        #\n",
    "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
    "        \n",
    "        pos=self.propagate(pos_edges, x=(x, x), size=size)\n",
    "        neg=self.propagate(neg_edges, x=(x, x), size=size)\n",
    "        out=self.lin_l(x) + self.lin_r(pos) - self.lin_r(neg)\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2)\n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your message function here.\n",
    "        # Hint: Look at the formulation of the mean aggregation function, focusing on \n",
    "        # what message each neighboring node passes.\n",
    "        #\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "        out = x_j\n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "\n",
    "        out = None\n",
    "\n",
    "        # The axis along which to index number of nodes.\n",
    "        node_dim = self.node_dim\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your aggregate function here.\n",
    "        # See here as how to use torch_scatter.scatter: \n",
    "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
    "        #\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "\n",
    "        out = torch_scatter.scatter(inputs, index, node_dim, dim_size=dim_size, reduce='mean')\n",
    "        ############################################################################\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "808605b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(data, args):\n",
    "    \n",
    "    print(\"Node task. test set size:\", np.sum(data[0]['test_mask'].numpy()))\n",
    "    print()\n",
    "    test_loader = loader = DataLoader(data, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
    "                            args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "          test_acc = test(test_loader, model)\n",
    "          test_accs.append(test_acc)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "    \n",
    "    return test_accs, losses, best_model, best_acc, test_loader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "866eb63173b86592158a964db75fecf14b959230d80ac60f512e985afb0979db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
